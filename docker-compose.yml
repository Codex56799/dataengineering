services:
  minio:
    image: minio/minio:latest
    container_name: de_minio
    env_file:
      - .env
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data       
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - de_net

  minio-init:
    image: minio/mc:latest
    container_name: de_minio_init
    depends_on:
      - minio
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c "
      mc alias set local http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} &&
      mc mb -p local/${S3_BUCKET_NAME} || true &&
      exit 0
      "
    networks:
      - de_net

  airflow-init:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: de_airflow_init
    env_file:
      - .env
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    volumes:
      - airflow_db:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./config:/opt/de_project/config:ro
      - ./data:/opt/de_project/data
      - ./warehouse:/opt/de_project/warehouse
    command: >
      bash -c "
        echo 'Initializing Airflow DB' &&
        airflow db migrate &&
        echo 'Creating admin user (reset to .env values)' &&
        airflow users delete --username \"${AIRFLOW_ADMIN_USER}\" || true &&
        airflow users create --username \"${AIRFLOW_ADMIN_USER}\" --password \"${AIRFLOW_ADMIN_PASSWORD}\" --firstname Admin --lastname User --role Admin --email \"${AIRFLOW_ADMIN_EMAIL}\" &&
        echo 'Airflow init done' &&
        exit 0
      "
    restart: "no"
    networks:
      - de_net

  airflow:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: de_airflow
    env_file:
      - .env
    environment:
      AIRFLOW_HOME: /opt/airflow
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"

      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}

      TZ: ${TZ}
    volumes:
      - airflow_db:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./config:/opt/de_project/config:ro
      - ./data:/opt/de_project/data
      - ./warehouse:/opt/de_project/warehouse
      - /var/run/docker.sock:/var/run/docker.sock 
    ports:
      - "8080:8080"
    command: >
      bash -c "
        airflow scheduler &
        exec airflow webserver
      "
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      spark:
        condition: service_started
      minio:
        condition: service_started
      minio-init:
        condition: service_completed_successfully
    networks:
      - de_net

  spark:
    build:
      context: ./infra/docker
      dockerfile: spark.Dockerfile
    container_name: de_spark
    user: "0:0"
    env_file:
      - .env
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}
      TZ: ${TZ}
    volumes:
      - ./spark_jobs:/opt/de_project/spark_jobs
      - ./config:/opt/de_project/config:ro
      - ./data:/opt/de_project/data
    command: >
      bash -c "
        tail -f /dev/null
      "
    networks:
      - de_net

  notebook:
    build:
      context: ./infra/docker
      dockerfile: notebook.Dockerfile
    container_name: de_notebook
    env_file:
      - .env
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}
      TZ: ${TZ}
    volumes:
      - ./notebooks:/opt/de_project/notebooks
      - ./config:/opt/de_project/config:ro
      - ./data:/opt/de_project/data
      - ./warehouse:/opt/de_project/warehouse
    ports:
      - "8888:8888"
    command: >
      jupyter lab --ip=0.0.0.0 --no-browser --allow-root --NotebookApp.token=''
    networks:
      - de_net

networks:
  de_net:
    driver: bridge

volumes:
  minio_data:
  airflow_db: